---
title: "Unit 10 BIO144 Course Content"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
```


## Introduction

On this web page you will find the homework, practical exercises and weekly quiz for Unit 10 of BIO144.

All other information for the course is on the OLAT course webpages, and web pages linked to from there: [OLAT BIO144 Info. Hub](https://lms.uzh.ch/auth/RepositoryEntry/17827987490/CourseNode/112943793799740)


## Homework

All homework is for your own practice and learning. It will not be marked or graded.

### Homework common to all weeks

* Review the material from the lecture(s) this week. Make sure you understand the concepts and ideas presented. Ensure you can follow any mathematical or statistical explanations. Ensure you can do the R that is needed for the week's learning objectives.

* When you find things you don't understand or have trouble doing (e.g., in R), make a note of these. You can then ask a teaching assistant (TA) for help during the practical session, and you can ask on the Discussion Forum on OLAT. You can also ask questions during the lectures.

## Videos for a different perspective

Here is a video that covers the basics of PCA:

<iframe width="560" height="315" src="https://www.youtube.com/embed/HMOI_lkzW08?si=Scw4q52bPiDLqHJO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

And here is a video about NMDS, mostly about how to implement it in R:

<iframe width="560" height="315" src="https://www.youtube.com/embed/h7OrVmT7Ja8?si=Q8lrQiDeTYCwAdxO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


## Practical part 1

By the end of this practical you should be able to:

- Explain *why* ordination methods are useful in biology
- Run a Principal Component Analysis (PCA)
- Interpret PCA scores and loadings
- Understand the role of scaling
- Avoid common misinterpretations of ordination plots



### Biological case study: plant communities along an environmental gradient

Imagine you are studying **plant communities along a moisture gradient**, ranging from dry grassland sites to wet meadow sites.

At each site, you measure:
- The abundance of several plant species
- An environmental variable representing soil moisture

Your goal is **not** to test a specific hypothesis, but to: *Explore multivariate structure in the community data.* This is a classic situation where **ordination** is useful. Specically, how does plant community composition change along the moisture gradient?

### Step 1: Create a dataset

For this practical, we will simulate data for 30 sites and 5 plant species. Copy the code into your script and use it to make a dataset.

```{r message = FALSE, echo = TRUE}
## Load necessary libraries
library(tidyverse)

## Set a random seed for reproducibility
set.seed(123)

## Number of sites
n_sites <- 30

## Number of species
n_species <- 5

## Simulate the soil moisture gradient, taking values from a uniform distribution
soil_moisture <- runif(n_sites, min = 10, max = 1000)

## make vector of average abundances for each species
## draw values from a log-normal distribution
abundance_intercepts <- rlnorm(n_species, meanlog = 3, sdlog = 0.5)

## make a vector of effects of soil moisture on each species
## draw values from a normal distribution with positive mean, so most species increase with moisture
abundance_slopes <- rnorm(n_species, mean = 1, sd = 1)

## Simulate the abundance of each species along the soil moisture gradient
community <- matrix(NA, nrow = n_sites, ncol = n_species)
for (i in 1:n_species) {
    mu <- pmax(0.1, abundance_intercepts[i] +
                 abundance_slopes[i] * soil_moisture)
  community[, i] <- MASS::rnegbin(n_sites, mu = mu, theta = 2)
}

## Name the species and convert to data frame
colnames(community) <- paste0("Species_", 1:n_species)
community <- as.data.frame(community)

## Add site IDs and soil moisture to the data frame
community <- community |> 
  mutate(Site = paste0("Site_", 1:n_sites),
         Soil_Moisture = soil_moisture) 
```


And here is the created dataset.

```{r}
community
```

```{r ord_q1, echo = FALSE}
learnr::question(
  "Which best describes the species data in this dataset?",
  answer("Multivariate response data", correct = TRUE),
  answer("Single response with one predictor"),
  answer("Time series data"),
  answer("Binary outcome data"),
  correct = "Yes, we have multiple species measured at each site — a multivariate response.",
  incorrect = "No, this dataset contains multiple species measured at each site, and this is the response we're interested in.",
  allow_retry = TRUE
)
```

### Step 2: Visualize species abundances

Before running PCA, it's useful to visualize the species abundances along the soil moisture gradient. And also to assess correlations among species.

An elegant method for making an appropriate visualisation is first to gather the data into long format, and then plot it with ggplot2.

```{r eval = FALSE, echo = TRUE}
## Gather data into long format
community_long <- community |> 
  pivot_longer(cols = starts_with("Species_"), 
               names_to = "Species", 
               values_to = "Abundance")
## Plot species abundances along soil moisture gradient
ggplot(community_long, aes(x = Soil_Moisture, y = Abundance, color = Species)) +
  geom_point() +
  labs(y = "Species Abundance", title = "Species Abundances along Soil Moisture Gradient")
```

Here's a rather geeky R question for you:


```{r ord_q2, echo = FALSE}
learnr::question(
  "Why is it generally better to use ggplot on the long-format version of the data, rather than creating separate plots or layers for each species?",
  answer("Because long-format data always produces more accurate plots"),
  answer("Because ggplot cannot plot wide-format data at all"),
 answer("Because the same code works for any number of species and any species names, without needing to change the code", correct = TRUE),
   answer("Because using multiple layers makes plots impossible to interpret"),
  correct = "Correct. Long-format data allows ggplot to map species to aesthetics automatically, making the code flexible and scalable.",
  incorrect = "Not quite. While long-format data is often more flexible for plotting, it's not about accuracy or impossibility of plotting wide-format data.",
  allow_retry = TRUE
  
)
```

We can see that we simulated species with different responses to soil moisture.

**Now, stop, and have a think about what you expect from the PCA. In particular, how much variance do you expect PC1 to explain? Why? This is really important to think about. Discuss with a neighbour or a TA if you are unsure. Write down what you think. (The question is essential how high dimensional is the data?**


Also, we see that some species have high average abundances, while others are generally rare. This means that some species will have a much larger influence on PCA results than others, unless we do some kind of standardization or transformation.

```{r ord_q3, echo = FALSE}
learnr::question(
  "How would standardising (scaling) the species variables affect the PCA in this practical?",
  answer("It ensures that all species contribute equally regardless of their absolute abundances", correct = TRUE),
  answer("It removes all correlations between species"),
  answer("It makes PCA unnecessary"),
  answer("It guarantees that PC1 will represent the moisture gradient"),
  correct = "Correct. Standardisation gives each species unit variance, preventing high-abundance species from dominating the ordination.",
  incorrect = "Not quite. Standardisation affects how variance is weighted, not correlations or ecological meaning.",
  allow_retry = TRUE
)
```

Let us standardise the species data before running PCA, so that all species contribute equally. Standardisation should include centering (make the mean = 0) and scaling (make the standard deviation = 1) of each variable. Try to make code for this yourself. If you get stuck, ask a neighbour or a TA for help, or look at the code in the Code snippets section of this web page.

```{r echo = FALSE}
## Standardise species data (mean = 0, sd = 1)
community_scaled <- community |> 
  select(starts_with("Species_")) |> 
  scale() |> 
  as.data.frame()
## Add site IDs and soil moisture back to the data frame
community_scaled <- community_scaled |> 
  mutate(Site = community$Site,
         Soil_Moisture = community$Soil_Moisture)
```

Check the scaling worked:

```{r}
community_scaled |> summarise(across(starts_with("Species_"),
                                     list(mean = mean, sd = sd)))
```

The mean of each species is approximately 0, and the standard deviation is 1. So yes, it worked... at least for me :)

### Step 2: Prepare data for PCA

PCA requires numeric variables only and typically works on a species matrix. So make a new data frame with only the species data.

```{r echo = FALSE}
## Create species matrix for PCA
species_matrix <- community_scaled |> 
  select(starts_with("Species_")) |> 
  as.matrix()
```

### Step 3: Run PCA

Now we can run PCA using the `prcomp()` function.

```{r pca_q4, echo = FALSE}
learnr::question(
  "Why is it reasonable to use `center = FALSE` and `scale. = FALSE` when calling `prcomp()` in this analysis?",
  answer("Because centring and scaling are not important for PCA"),
   answer("Because the data have already been centred and scaled beforehand", correct = TRUE),
 answer("Because `prcomp()` always centres and scales the data automatically"),
  answer("Because centring and scaling only matter for plotting"),
  correct = "Correct. If the data have already been centred and scaled, repeating these steps inside `prcomp()` would be redundant.",
  incorrect = "Not quite. Centring and scaling are important for PCA, but they do not need to be repeated if already done.",
  allow_retry = TRUE
)
```

```{r echo = TRUE}
## Run PCA
pca_result <- prcomp(species_matrix, center = FALSE, scale. = FALSE)
```

### Step 4: Examine PCA results

You can examine the PCA results using the `summary()` function.

```{r eval = FALSE}
## Summarize PCA results
summary(pca_result)
```

```{r quiz-pca-pc1-variation, echo=FALSE}
learnr::question_numeric(
  "How much **variation** is represented in the **first principal component (PC1)**?\n\nGive your answer as a **percentage**, rounded to **one decimal place**.",
  
  learnr::answer(47.3, correct = TRUE),
  
  correct = "Correct! The first principal component explains 47.3% of the total variation.",
  incorrect = "Not quite. Check the proportion of variance explained by PC1 and convert it to a percentage, rounded to one decimal place.",
  allow_retry = TRUE
)
```

```{r quiz-pca-why-pc1-so-much, echo=FALSE}
learnr::question(
  "Why is **so much variation** explained by the **first principal component (PC1)** alone?",
  
   learnr::answer(
    "Because PCA always forces the first axis to explain most of the variation."
  ),
  learnr::answer(
    "Because the data were standardised before running PCA."
  ),
   learnr::answer(
    "Because the original variables are all strongly correlated with each other and largely indicate the same single underlying feature (soil moisture).",
    correct = TRUE
  ),

  learnr::answer(
    "Because the number of observations is much larger than the number of variables."
  ),
  learnr::answer(
    "Because PCA removes noise from the data."
  ),
  
  correct = "Correct! When variables are strongly correlated and measure a common underlying property (such as overall size), most of the variation lies along a single dominant axis, which PCA captures as PC1.",
  incorrect = "Think about the relationships among the original variables and what they represent biologically.",
  allow_retry = TRUE
)
```

### Step 5: Visualize PCA results

Create a biplot to visualize the PCA results.

```{r eval = FALSE}
ggplot() +
  geom_point(aes(x = pca_result$x[,1], y = pca_result$x[,2],
                 color = community_scaled$Soil_Moisture)) +
  labs(x = "PC1", y = "PC2", color = "Soil Moisture") 
```


### Step 6: Interpret PCA results more

The loadings indicate how each original variable contributes to each principal component.

```{r eval = FALSE}
## Get PCA loadings
loadings <- pca_result$rotation
loadings
```

```{r quiz-pca-negative-loadings, echo=FALSE}
learnr::question(
  "Which of the species have **negative loadings on the first principal component (PC1)**?",
  
  learnr::answer(
    "Species 1 and Species 3",
    correct = TRUE
  ),
  learnr::answer(
    "Species 1 only"
  ),
  learnr::answer(
    "Species 2 and Species 3"
  ),
  learnr::answer(
    "Species 2 only"
  ),
  learnr::answer(
    "None of the species"
  ),
  
  correct = "Correct! Species 1 and Species 3 have negative loadings on PC1, meaning they lie on the opposite side of the main size-related gradient captured by the first principal component.",
  incorrect = "Check the sign of the PC1 loadings for each species. Look for those with values less than zero.",
  allow_retry = TRUE
)
```

Recall that we simulated the data, and specified the effects of soil moisture on each species. Now check whether the PCA loadings align with these effects. The effects are in the `abundance_slopes` vector created during data simulation.


### Step 7: Linking ordination to soil moisture

Based on your PCA results, what conclusions can you draw about the plant communities along the soil moisture gradient? Consider how species abundances change with moisture and how this is reflected in the PCA.

### Summary

In this practical exercise you used Principal Component Analysis to explore structure in a multivariate ecological dataset. The analysis showed how ordination can reduce complex species data to a small number of synthetic axes that capture dominant patterns of variation, making high-dimensional data easier to visualise and reason about. By working with loadings, you saw how sites are positioned in ordination space, and how these positions reflect similarities and differences in community composition. The practical also highlighted the importance of centring and scaling, and how choices made during data preparation can strongly influence the resulting ordination.

It is important to be clear about what PCA does and does not provide. PCA is well suited for exploratory analysis and for generating ideas about possible ecological gradients or groupings, but it is not a hypothesis-testing tool and does not establish causal relationships. Apparent patterns in ordination space can be shaped by noise, preprocessing decisions, or a small number of dominant variables. Interpreting PCA axes as real ecological gradients without additional evidence is therefore risky. Ordination compresses information, which means that some variation is inevitably lost and small visual differences may not be meaningful. A thoughtful analyst treats ordination as a starting point rather than a conclusion, using it to guide further modelling and more explicit statistical analysis.




## Practical part 2

Case study: Diet and the human gut microbiome. The human gut microbiome plays a crucial role in digestion, metabolism, and health. Diet is known to be one of the strongest drivers of gut microbiome composition, influencing which microbial taxa thrive in the gut.

In this practical exercise, we investigate whether diet type is associated with differences in gut microbiome community composition.

Study design:

* Stool samples were collected from 60 adult individuals
* Individuals followed one of three long-term diets: Omnivorous, Vegetarian, Vegan
* DNA was extracted from each sample and analysed using shotgun metagenomic sequencing.
* Sequencing reads were assigned to microbial taxa, producing relative abundance estimates for a set of bacterial taxa.

Biological question: Does gut microbiome composition differ among individuals with different diets?

To address this, we will use ordination (NMDS) based on community dissimilarity.

Structure of the dataset:

* Each row = one individual
* Each column = relative abundance of a microbial taxon
* Values represent relative abundance (proportions summing to ~1)
* Additional metadata columns: SampleID, and Diet

This structure is typical of microbiome data used in ordination analyses.

Over to you! .. Make a script, make it beautiful, get the dataset (`microbiome_data.csv`), load it into R.

```{r eval = FALSE}
# Set seed for reproducibility
set.seed(144)

# Number of samples
n_samples <- 60

# Diet groups
diet <- factor(rep(c("Omnivore", "Vegetarian", "Vegan"), each = 20))

# Number of microbial taxa
n_taxa <- 200

# Base community composition (shared taxa)
base_abundance <- rgamma(n_taxa, shape = 2, scale = 1)

# Diet-specific effects
diet_effects <- list(
  Omnivore    = rlnorm(n_taxa, meanlog = 0, sdlog = 0.1),
  Vegetarian  = rlnorm(n_taxa, meanlog = 0.2, sdlog = 0.1),
  Vegan       = rlnorm(n_taxa, meanlog = 0.4, sdlog = 0.1)
)

# Generate abundance matrix
abundance_matrix <- matrix(NA, nrow = n_samples, ncol = n_taxa)

for (i in 1:n_samples) {
  group <- diet[i]
  lambda <- base_abundance * diet_effects[[as.character(group)]]
  abundance_matrix[i, ] <- rgamma(n_taxa, shape = lambda, scale = 1)
}

# Convert to relative abundances
abundance_matrix <- abundance_matrix / rowSums(abundance_matrix)

# Add column names
colnames(abundance_matrix) <- paste0("OTU_", 1:n_taxa)

# Create final dataset
microbiome_data <- data.frame(
  SampleID = paste0("S", 1:n_samples),
  Diet = diet,
  abundance_matrix
)
write_csv(microbiome_data, "~/Desktop/microbiome_data.csv")
```

```{r echo = FALSE, message = FALSE}
biom <- read_csv("https://raw.githubusercontent.com/opetchey/BIO144/refs/heads/master/3_datasets/microbiome_data.csv")
```

The first step in the analysis is to calculate pairwise dissimilarities among samples based on their community composition. Use Bray–Curtis dissimilarity, which is well suited for relative abundance data. Use the `vegdist` function from the `vegan` package.

```{r echo = FALSE, message = FALSE}
library(vegan)
D <- vegdist(biom |> select(starts_with("OTU_")), method = "bray")
```

Then make a Non-metric Multidimensional Scaling (NMDS) ordination based on the Bray–Curtis dissimilarity matrix. Use the `metaMDS` function from the `vegan` package. Choose appropriate parameters, based on information in the course book.

```{r echo = FALSE, message = FALSE, eval = FALSE}
set.seed(144)
nmds_result <- metaMDS(D, k = 10, trymax = 100)
```

What is the stress value of the NMDS solution? Is it acceptable? Recall that stress < 0.1 is considered a good fit, while stress > 0.2 indicates a poor fit.

Look at the stresplot to assess the NMDS fit. What is the linear fit, r-squared value? Is it acceptable? I (Owen) found less than 0.7 with `k = 3`, which is not great, but OK for ecological data. I increased to `k = 10` and got r-squared = 0.86, which is very good. So the data seems to need a high-dimensional solution to get a good fit.

```{r eval = FALSE}
# Procrustes plot to visualize NMDS fit
stressplot(nmds_result)
```

Finally, visualize the NMDS results, colouring points by diet group to see if there are differences in community composition among diets.

```{r eval = FALSE}
# Extract NMDS scores
# Create a data frame with NMDS scores and diet information
nmds_scores <- as.data.frame(nmds_result$points)
nmds_scores$Diet <- biom$Diet
# Plot NMDS results
ggplot(nmds_scores, aes(x = MDS1, y = MDS2, color = Diet)) +
  geom_point(size = 3) +
  labs(title = "NMDS of Gut Microbiome Composition by Diet",
       x = "NMDS1", y = "NMDS2")
```

Write a few sentences about the patterns you see in the NMDS plot. Do different diet groups cluster separately? What does this suggest about the influence of diet on gut microbiome composition? What else can you see?

### Heads up

Analysis of genomic data, including metagenomics, proteomics, and transcriptomics, is a rapidly evolving field. New methods and best practices are continually being developed. The approach outlined here is a basic introduction to ordination of microbiome data, but more advanced techniques exist that may provide deeper insights. As you progress in your studies, consider exploring additional methods such as phylogenetic ordination, machine learning approaches, and network analysis to further investigate complex biological datasets. One place to start is the phyloseq R package, which provides tools for microbiome data analysis incorporating phylogenetic information. https://joey711.github.io/phyloseq/


## Weekly Quiz


```{r quiz-ordination-pca-purpose, echo=FALSE}
learnr::question(
  "What is the main goal of Principal Component Analysis (PCA)?",
  
  learnr::answer("To cluster observations into discrete groups."),
  learnr::answer("To test for differences among groups using a statistical test."),
  learnr::answer(
    "To reduce the dimensionality of multivariate data while retaining as much variation as possible.",
    correct = TRUE
  ),
  learnr::answer("To maximise distances among observations."),
  
  correct = "Correct! PCA reduces dimensionality by finding axes that explain the maximum variance.",
  incorrect = "Think about variance and dimensionality reduction.",
  allow_retry = TRUE
)
```


```{r quiz-ordination-pca-r, echo=FALSE}
learnr::question(
  "Which R function is most commonly used to perform PCA on a numeric data matrix?",
  
  learnr::answer("metaMDS()"),
  learnr::answer(
    "prcomp()",
    correct = TRUE
  ),
  learnr::answer("lm()"),
  learnr::answer("dist()"),
  
  correct = "Correct! prcomp() is the standard function for PCA in R.",
  incorrect = "Look for the base R function designed for PCA.",
  allow_retry = TRUE
)
```


```{r quiz-ordination-pca-scaling, echo=FALSE}
learnr::question(
  "Why is it often important to scale variables before performing PCA?",
  
  learnr::answer("Because PCA only works on scaled data."),
  learnr::answer("Because scaling increases the number of principal components."),
  learnr::answer(
    "Because variables measured on larger scales would otherwise dominate the analysis.",
    correct = TRUE
  ),
  learnr::answer("Because PCA assumes normally distributed variables."),
  
  correct = "Correct! Without scaling, variables with large variances can dominate the principal components.",
  incorrect = "Think about the effect of measurement units on variance.",
  allow_retry = TRUE
)
```


```{r quiz-ordination-nmds-concept, echo=FALSE}
learnr::question(
  "What aspect of the data does Non-metric Multidimensional Scaling (NMDS) aim to preserve?",
  
  learnr::answer("Exact Euclidean distances between observations."),
  learnr::answer(
    "The rank order of dissimilarities among observations.",
    correct = TRUE
  ),
  learnr::answer("The variance–covariance structure of the variables."),
  learnr::answer("Linear relationships among variables."),
  
  correct = "Correct! NMDS focuses on preserving the rank order of dissimilarities.",
  incorrect = "NMDS is non-metric — think about ranks, not exact distances.",
  allow_retry = TRUE
)
```


```{r quiz-ordination-nmds-stress, echo=FALSE}
learnr::question(
  "An NMDS solution has a stress value of 0.12. How would you interpret this?",
  
  learnr::answer(
    "The ordination provides a good representation of the data.",
    correct = TRUE
  ),
  learnr::answer("The ordination is unreliable and should not be used."),
  learnr::answer("The data are normally distributed."),
  learnr::answer("The distances are perfectly preserved."),
  
  correct = "Correct! Stress values below about 0.2 are generally considered acceptable in ecology.",
  incorrect = "Recall the common rules of thumb for NMDS stress values.",
  allow_retry = TRUE
)
```



```{r quiz-ordination-nmds-r, echo=FALSE}
learnr::question(
  "Which R function from the vegan package is typically used to perform NMDS?",
  
  learnr::answer("prcomp()"),
  learnr::answer("cmdscale()"),
  learnr::answer("vegdist()"),
  learnr::answer(
    "metaMDS()",
    correct = TRUE
  ),

  
  correct = "Correct! metaMDS() is the standard function for NMDS in vegan.",
  incorrect = "Look for the function that combines distance calculation and ordination.",
  allow_retry = TRUE
)
```



```{r quiz-ordination-nmds-axes, echo=FALSE}
learnr::question(
  "Which statement about NMDS axes is correct?",
  
  learnr::answer(
    "The axes have arbitrary orientation and scale, and should not be interpreted like PCA axes.",
    correct = TRUE
  ),
  learnr::answer("The first axis always explains the most variation."),
  learnr::answer("The axes correspond to original variables."),
  learnr::answer("Axis labels represent percentages of variance explained."),
  
  correct = "Correct! NMDS axes are arbitrary and do not have direct interpretive meaning.",
  incorrect = "Think about how NMDS differs fundamentally from PCA.",
  allow_retry = TRUE
)
```


```{r quiz-ordination-pca-vs-nmds, echo=FALSE}
learnr::question(
  "Which situation would most strongly favour using NMDS rather than PCA?",
  
  learnr::answer("When variables are measured in the same units."),
  learnr::answer(
    "When the data are non-linear, non-normal, and based on ecological dissimilarities.",
    correct = TRUE
  ),
  learnr::answer("When the goal is hypothesis testing."),
  learnr::answer("When the covariance matrix is well behaved."),
  
  correct = "Correct! NMDS is well suited to non-linear, non-normal ecological community data.",
  incorrect = "Consider the assumptions underlying PCA.",
  allow_retry = TRUE
)
```


```{r quiz-ordination-gotcha-interpretation, echo=FALSE}
learnr::question(
  "Which is the most appropriate way to interpret patterns seen in an ordination plot?",
  
  learnr::answer("Exact distances between points represent precise differences."),
  learnr::answer("Ordination plots provide causal explanations."),
  learnr::answer("The axes indicate specific biological mechanisms."),
    learnr::answer(
    "Broad patterns and group separation are informative, but fine-scale distances should be interpreted cautiously.",
    correct = TRUE
  ),

  correct = "Correct! Ordination is exploratory and best used to identify broad patterns.",
  incorrect = "Ordination is not designed for precise or causal interpretation.",
  allow_retry = TRUE
)
```


## Code snippets

Here are some code snippets that you may find useful for this unit.

```{r echo = TRUE}
## Standardise species data (mean = 0, sd = 1)
community_scaled <- community |> 
  select(starts_with("Species_")) |> 
  scale() |> 
  as.data.frame()
## Add site IDs and soil moisture back to the data frame
community_scaled <- community_scaled |> 
  mutate(Site = community$Site,
         Soil_Moisture = community$Soil_Moisture)
```




